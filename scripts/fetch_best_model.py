"""
Fetch Best Model from MLflow Registry
Downloads the best performing model from DagsHub MLflow for deployment
"""
import os
import sys
import joblib
import mlflow
from mlflow.tracking import MlflowClient
from pathlib import Path


def setup_mlflow():
    """Configure MLflow with DagsHub credentials"""
    tracking_uri = os.getenv(
        'MLFLOW_TRACKING_URI',
        'https://dagshub.com/abdulhananch404/MLOPS_Project.mlflow'
    )
    mlflow.set_tracking_uri(tracking_uri)
    
    # Set authentication if available
    dagshub_token = os.getenv('DAGSHUB_TOKEN')
    if dagshub_token:
        os.environ['MLFLOW_TRACKING_USERNAME'] = os.getenv(
            'MLFLOW_TRACKING_USERNAME', 'abdulhananch404'
        )
        os.environ['MLFLOW_TRACKING_PASSWORD'] = dagshub_token
    
    return MlflowClient()


def find_best_model(client, experiment_name="crypto-price-prediction"):
    """Find the best model based on RMSE from all experiments"""
    
    # Try to get the experiment
    experiment = client.get_experiment_by_name(experiment_name)
    
    if experiment is None:
        # Search all experiments
        experiments = client.search_experiments()
        if not experiments:
            print("No experiments found in MLflow")
            return None, None
        
        # Use the first available experiment
        experiment = experiments[0]
        print(f"Using experiment: {experiment.name}")
    
    # Search for runs sorted by RMSE
    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        filter_string="",
        order_by=["metrics.rmse ASC"],
        max_results=10
    )
    
    if not runs:
        print("No runs found in the experiment")
        return None, None
    
    best_run = runs[0]
    print(f"\nðŸ† Best Model Found:")
    print(f"   Run ID: {best_run.info.run_id}")
    print(f"   Model: {best_run.data.params.get('model_name', 'Unknown')}")
    print(f"   RMSE: {best_run.data.metrics.get('rmse', 'N/A'):.4f}")
    print(f"   R2: {best_run.data.metrics.get('r2', 'N/A'):.4f}")
    
    return best_run, experiment


def download_model(client, run, output_dir="models"):
    """Download the model artifacts from MLflow"""
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    run_id = run.info.run_id
    
    # List artifacts
    artifacts = client.list_artifacts(run_id)
    print(f"\nAvailable artifacts: {[a.path for a in artifacts]}")
    
    # Download model artifacts
    model_downloaded = False
    
    for artifact in artifacts:
        artifact_path = artifact.path
        
        # Download model file
        if artifact_path.endswith('.joblib') or artifact_path == 'model':
            local_path = mlflow.artifacts.download_artifacts(
                run_id=run_id,
                artifact_path=artifact_path,
                dst_path=str(output_path)
            )
            print(f"âœ“ Downloaded: {artifact_path} -> {local_path}")
            model_downloaded = True
    
    # Also try to download scaler if exists
    try:
        scaler_path = mlflow.artifacts.download_artifacts(
            run_id=run_id,
            artifact_path="scaler.joblib",
            dst_path=str(output_path)
        )
        print(f"âœ“ Downloaded scaler: {scaler_path}")
    except Exception:
        print("â„¹ No scaler artifact found in this run")
    
    return model_downloaded


def ensure_model_exists(output_dir="models"):
    """Ensure model files exist for deployment"""
    output_path = Path(output_dir)
    model_files = list(output_path.glob("*.joblib"))
    
    if not model_files:
        print("\nâš  No model files found. Creating placeholder model...")
        # Create a simple placeholder model for testing
        from sklearn.linear_model import Ridge
        from sklearn.preprocessing import StandardScaler
        import numpy as np
        
        # Create and save a simple model
        model = Ridge(alpha=1.0)
        X_dummy = np.random.randn(100, 5)
        y_dummy = np.random.randn(100)
        model.fit(X_dummy, y_dummy)
        
        scaler = StandardScaler()
        scaler.fit(X_dummy)
        
        model_path = output_path / "best_model_ridge.joblib"
        scaler_path = output_path / "scaler.joblib"
        
        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)
        
        print(f"âœ“ Created placeholder model: {model_path}")
        print(f"âœ“ Created placeholder scaler: {scaler_path}")
        return True
    
    print(f"\nâœ“ Model files found: {[f.name for f in model_files]}")
    return True


def main():
    print("=" * 60)
    print("Fetching Best Model from MLflow")
    print("=" * 60)
    
    try:
        # Setup MLflow client
        client = setup_mlflow()
        
        # Find the best model
        best_run, experiment = find_best_model(client)
        
        if best_run:
            # Download model artifacts
            success = download_model(client, best_run)
            
            if success:
                print("\nâœ… Model artifacts downloaded successfully!")
            else:
                print("\nâš  Could not download model, using existing files...")
        else:
            print("\nâš  No runs found in MLflow")
        
        # Ensure we have model files for deployment
        ensure_model_exists()
        
        print("\n" + "=" * 60)
        print("Model Fetch Complete!")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâš  Error fetching model from MLflow: {e}")
        print("Ensuring model files exist for deployment...")
        ensure_model_exists()


if __name__ == "__main__":
    main()
